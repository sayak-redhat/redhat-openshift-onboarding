# ğŸ“š Phase 4: Advanced Internals Study Guide
## Deep Dive into Kubernetes & OpenShift Architecture

---

## Table of Contents

1. [Module 1: API Server Deep Dive](#module-1-api-server-deep-dive)
2. [Module 2: etcd - The Brain of Kubernetes](#module-2-etcd---the-brain-of-kubernetes)
3. [Module 3: Scheduler Internals](#module-3-scheduler-internals)
4. [Module 4: Controller Manager](#module-4-controller-manager)
5. [Module 5: Networking Internals (CNI)](#module-5-networking-internals-cni)
6. [Module 6: Storage Internals (CSI)](#module-6-storage-internals-csi)
7. [Module 7: Advanced Debugging](#module-7-advanced-debugging)
8. [Module 8: Performance & Troubleshooting](#module-8-performance--troubleshooting)

---

# Module 1: API Server Deep Dive

## 1.1 What is the API Server?

**Simple Explanation**: The API Server is the front door to Kubernetes. Every request (from kubectl, operators, kubelet) goes through it. It validates, processes, and stores requests in etcd.

**Real-life Analogy**: The API Server is like a bank teller. Everyone who wants to do something with their money (resources) has to go through the teller (API Server), who validates their identity, checks their permissions, and processes their request.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          API Server Request Flow                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   kubectl apply -f pod.yaml                                                  â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â”‚ HTTPS request                                                      â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                       1. AUTHENTICATION                              â”‚   â”‚
â”‚   â”‚                       "Who are you?"                                 â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Methods:                                                           â”‚   â”‚
â”‚   â”‚   â€¢ X.509 client certificates                                       â”‚   â”‚
â”‚   â”‚   â€¢ Bearer tokens (ServiceAccount tokens)                           â”‚   â”‚
â”‚   â”‚   â€¢ OpenID Connect (OAuth)                                          â”‚   â”‚
â”‚   â”‚   â€¢ Webhook authentication                                          â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â”‚ User: "sayadas", Groups: ["developers"]                           â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                       2. AUTHORIZATION                               â”‚   â”‚
â”‚   â”‚                       "Can you do this?"                             â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Checks RBAC:                                                       â”‚   â”‚
â”‚   â”‚   â€¢ Does user have Role/ClusterRole?                                â”‚   â”‚
â”‚   â”‚   â€¢ Does role allow "create" on "pods"?                             â”‚   â”‚
â”‚   â”‚   â€¢ Is action allowed in this namespace?                            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â”‚ Authorized!                                                        â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                     3. ADMISSION CONTROL                             â”‚   â”‚
â”‚   â”‚                     "Should we allow this?"                          â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚   â”‚
â”‚   â”‚   â”‚   Mutating      â”‚ â†’  â”‚   Validating    â”‚                        â”‚   â”‚
â”‚   â”‚   â”‚   Webhooks      â”‚    â”‚   Webhooks      â”‚                        â”‚   â”‚
â”‚   â”‚   â”‚                 â”‚    â”‚                 â”‚                        â”‚   â”‚
â”‚   â”‚   â”‚ â€¢ Add defaults  â”‚    â”‚ â€¢ Check policy  â”‚                        â”‚   â”‚
â”‚   â”‚   â”‚ â€¢ Inject sidecarâ”‚    â”‚ â€¢ Validate spec â”‚                        â”‚   â”‚
â”‚   â”‚   â”‚ â€¢ Add labels    â”‚    â”‚ â€¢ Deny bad pods â”‚                        â”‚   â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â”‚ Admitted!                                                          â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                          4. STORAGE                                  â”‚   â”‚
â”‚   â”‚                          "Store in etcd"                             â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Pod object serialized and stored in etcd                          â”‚   â”‚
â”‚   â”‚   Key: /registry/pods/namespace/pod-name                            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â”‚ Stored!                                                            â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                       5. NOTIFICATION                                â”‚   â”‚
â”‚   â”‚                       "Tell watchers"                                â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Controllers/kubelet watching "pods" get notified:                 â”‚   â”‚
â”‚   â”‚   "New pod created! Go do something!"                               â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1.2 Admission Controllers

Admission controllers are plugins that intercept requests AFTER authentication/authorization but BEFORE the object is stored.

### Built-in Admission Controllers

| Controller | What it does |
|------------|--------------|
| **NamespaceLifecycle** | Prevents operations in non-existent namespaces |
| **LimitRanger** | Enforces default limits on resources |
| **ServiceAccount** | Auto-creates ServiceAccount and token |
| **PodSecurity** | Enforces Pod Security Standards |
| **ResourceQuota** | Enforces namespace quotas |
| **MutatingAdmissionWebhook** | Calls external webhooks to modify |
| **ValidatingAdmissionWebhook** | Calls external webhooks to validate |

### How Webhooks Work

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Admission Webhook Flow                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   1. Request comes in: "Create Pod X"                                        â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   2. API Server calls Mutating Webhooks                                      â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚      â”‚  Webhook 1: Istio Sidecar Injector                              â”‚    â”‚
â”‚      â”‚  "Add istio-proxy container to this pod"                        â”‚    â”‚
â”‚      â”‚                                                                  â”‚    â”‚
â”‚      â”‚  Webhook 2: SPIFFE CSI Driver Webhook                           â”‚    â”‚
â”‚      â”‚  "Add CSI volume for SPIFFE workload API"                       â”‚    â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼ (Pod now modified with sidecars/volumes)                          â”‚
â”‚                                                                              â”‚
â”‚   3. API Server calls Validating Webhooks                                    â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚      â”‚  Webhook 1: OPA/Gatekeeper                                      â”‚    â”‚
â”‚      â”‚  "Check: Is image from allowed registry?"                       â”‚    â”‚
â”‚      â”‚  "Check: Does pod have required labels?"                        â”‚    â”‚
â”‚      â”‚                                                                  â”‚    â”‚
â”‚      â”‚  Webhook 2: Security Policy Webhook                             â”‚    â”‚
â”‚      â”‚  "Check: Is pod not running as root?"                           â”‚    â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼ (All validations passed)                                          â”‚
â”‚                                                                              â”‚
â”‚   4. Store in etcd                                                           â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1.3 Watching API Server

```bash
# Enable verbose output to see API calls
kubectl get pods -v=8

# Sample output shows:
# GET https://api.cluster.example.com:6443/api/v1/namespaces/default/pods
# Request Headers:
#   Accept: application/json
#   User-Agent: kubectl/v1.28.0
# Response Status: 200 OK

# Watch API server metrics
oc get --raw /metrics | grep apiserver_request

# Check API server logs (on master node)
oc debug node/<master-node>
chroot /host
crictl logs $(crictl ps --name=kube-apiserver -q)

# Check enabled admission plugins
oc get cm -n openshift-kube-apiserver config -o yaml | grep -A 50 "admission"
```

---

# Module 2: etcd - The Brain of Kubernetes

## 2.1 What is etcd?

**Simple Explanation**: etcd is a distributed key-value database that stores ALL Kubernetes state. Every pod, service, secret, configmap - everything is stored in etcd.

**Real-life Analogy**: etcd is like the hotel's master registry book. It knows every guest (pod), every room assignment (scheduling), every special request (configs). If you lose this book, the hotel can't function.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           etcd Data Model                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   etcd stores data as key-value pairs organized hierarchically:             â”‚
â”‚                                                                              â”‚
â”‚   /registry/                                                                 â”‚
â”‚   â”œâ”€â”€ pods/                                                                  â”‚
â”‚   â”‚   â”œâ”€â”€ default/                                                          â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ nginx-abc123    â†’ {pod spec JSON}                            â”‚
â”‚   â”‚   â”‚   â””â”€â”€ redis-xyz789    â†’ {pod spec JSON}                            â”‚
â”‚   â”‚   â””â”€â”€ kube-system/                                                       â”‚
â”‚   â”‚       â””â”€â”€ coredns-xxx     â†’ {pod spec JSON}                            â”‚
â”‚   â”‚                                                                          â”‚
â”‚   â”œâ”€â”€ services/                                                              â”‚
â”‚   â”‚   â””â”€â”€ default/                                                          â”‚
â”‚   â”‚       â””â”€â”€ kubernetes      â†’ {service spec JSON}                         â”‚
â”‚   â”‚                                                                          â”‚
â”‚   â”œâ”€â”€ secrets/                                                               â”‚
â”‚   â”‚   â””â”€â”€ default/                                                          â”‚
â”‚   â”‚       â””â”€â”€ my-secret       â†’ {secret data JSON}                          â”‚
â”‚   â”‚                                                                          â”‚
â”‚   â”œâ”€â”€ configmaps/                                                            â”‚
â”‚   â”‚   â””â”€â”€ kube-system/                                                       â”‚
â”‚   â”‚       â””â”€â”€ kube-proxy      â†’ {configmap data JSON}                       â”‚
â”‚   â”‚                                                                          â”‚
â”‚   â””â”€â”€ customresources/                                                       â”‚
â”‚       â””â”€â”€ spireservers/                                                      â”‚
â”‚           â””â”€â”€ cluster         â†’ {spireserver spec JSON}                     â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 2.2 etcd Cluster Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      etcd Cluster (3 nodes for HA)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚   etcd-0        â”‚    â”‚   etcd-1        â”‚    â”‚   etcd-2        â”‚         â”‚
â”‚   â”‚   (Leader)      â”‚â—„â”€â”€â–ºâ”‚   (Follower)    â”‚â—„â”€â”€â–ºâ”‚   (Follower)    â”‚         â”‚
â”‚   â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚         â”‚
â”‚   â”‚   Handles all   â”‚    â”‚   Replicates    â”‚    â”‚   Replicates    â”‚         â”‚
â”‚   â”‚   writes        â”‚    â”‚   from leader   â”‚    â”‚   from leader   â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚            â”‚                     â”‚                     â”‚                     â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                  â”‚                                           â”‚
â”‚                          Raft Consensus                                      â”‚
â”‚                                                                              â”‚
â”‚   â€¢ Writes go to leader, replicated to followers                            â”‚
â”‚   â€¢ Reads can go to any node                                                 â”‚
â”‚   â€¢ Quorum (2 of 3) required for writes                                     â”‚
â”‚   â€¢ If leader fails, new election happens                                   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 2.3 etcd Operations

```bash
# Access etcd on OpenShift
oc debug node/<master-node>
chroot /host

# Find etcd pod
crictl ps | grep etcd

# Access etcd shell
oc exec -it etcd-<master-node> -n openshift-etcd -- /bin/sh

# Inside etcd pod, use etcdctl
etcdctl --endpoints=https://localhost:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  endpoint status

# List keys (careful - don't do in production!)
etcdctl ... get / --prefix --keys-only | head -50

# Check cluster health
etcdctl ... endpoint health

# Check cluster member list
etcdctl ... member list

# Defragment (maintenance)
etcdctl ... defrag

# Check database size
etcdctl ... endpoint status --write-out=table
```

## 2.4 etcd Backup & Restore

```bash
# Backup etcd (CRITICAL for disaster recovery!)
etcdctl snapshot save /backup/etcd-snapshot.db

# Verify backup
etcdctl snapshot status /backup/etcd-snapshot.db --write-out=table

# Restore (emergency only!)
etcdctl snapshot restore /backup/etcd-snapshot.db \
  --data-dir=/var/lib/etcd-restore

# OpenShift specific backup
oc get etcdbackups -n openshift-etcd

# Create backup via OpenShift
cat <<EOF | oc apply -f -
apiVersion: operator.openshift.io/v1alpha1
kind: EtcdBackup
metadata:
  name: backup-$(date +%Y%m%d)
  namespace: openshift-etcd
spec:
  pvcName: etcd-backup-pvc
EOF
```

---

# Module 3: Scheduler Internals

## 3.1 How the Scheduler Works

**Simple Explanation**: The Scheduler decides which node should run a pod. It finds nodes that CAN run the pod, scores them, and picks the best one.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Scheduler Decision Process                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   New Pod (Pending, no node assigned)                                        â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    1. FILTERING                                      â”‚   â”‚
â”‚   â”‚                    "Which nodes CAN run this pod?"                   â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Checks:                                                            â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ NodeSelector: Does node have required labels?                 â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Resources: Does node have enough CPU/memory?                  â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Taints: Does pod tolerate node's taints?                      â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Affinity: Does pod's affinity match node?                     â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Ports: Is required hostPort available?                        â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Volume: Can required volumes be mounted?                      â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Available Nodes: [node-1, node-2, node-3]                         â”‚   â”‚
â”‚   â”‚   After filtering: [node-1, node-3]  (node-2 failed resource check) â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    2. SCORING                                        â”‚   â”‚
â”‚   â”‚                    "Which node is BEST?"                             â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Scoring plugins (each gives 0-100):                               â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ LeastRequestedPriority: More free resources = higher score   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ BalancedResourceAllocation: Even CPU/memory = higher score   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ NodeAffinity: Preferred affinity match = higher score        â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ InterPodAffinity: Pod affinity match = higher score          â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ImageLocality: Image already on node = higher score          â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   node-1: 85 points                                                  â”‚   â”‚
â”‚   â”‚   node-3: 72 points                                                  â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    3. BINDING                                        â”‚   â”‚
â”‚   â”‚                    "Assign pod to winning node"                      â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Winner: node-1 (85 points)                                        â”‚   â”‚
â”‚   â”‚   Pod updated: spec.nodeName = "node-1"                             â”‚   â”‚
â”‚   â”‚   kubelet on node-1 sees pod and starts it                          â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 3.2 Scheduling Constraints

### Node Selector

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  nodeSelector:
    gpu: "true"           # Only schedule on nodes with label gpu=true
  containers:
  - name: app
    image: my-gpu-app
```

### Affinity & Anti-Affinity

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: web-pod
spec:
  affinity:
    # Node affinity - prefer certain nodes
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: zone
            operator: In
            values: ["us-west-1a", "us-west-1b"]
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: type
            operator: In
            values: ["high-memory"]
    
    # Pod affinity - schedule near other pods
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: cache
        topologyKey: "kubernetes.io/hostname"
    
    # Pod anti-affinity - spread pods apart
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web
          topologyKey: "kubernetes.io/hostname"
```

### Taints and Tolerations

```bash
# Add taint to node (repels pods)
oc adm taint nodes node-1 dedicated=database:NoSchedule

# Pod must have toleration to run on tainted node
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: database-pod
spec:
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "database"
    effect: "NoSchedule"
```

## 3.3 Debugging Scheduling

```bash
# See why pod is pending
oc describe pod pending-pod | grep -A 20 "Events:"

# Common messages:
# - "Insufficient cpu" - no node has enough CPU
# - "Insufficient memory" - no node has enough memory
# - "node(s) didn't match node selector" - no node has required label
# - "node(s) had taint that pod didn't tolerate"

# Check node capacity
oc describe node node-1 | grep -A 10 "Allocatable:"

# Check what's using resources on node
oc describe node node-1 | grep -A 30 "Non-terminated Pods:"

# Check scheduler logs
oc logs -n openshift-kube-scheduler kube-scheduler-<master>
```

---

# Module 4: Controller Manager

## 4.1 What is the Controller Manager?

**Simple Explanation**: The Controller Manager runs all the built-in controllers that maintain cluster state. Each controller watches specific resources and makes changes to achieve desired state.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Built-in Controllers                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                 Deployment Controller                                â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Watches: Deployments                                              â”‚   â”‚
â”‚   â”‚   Creates: ReplicaSets                                              â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   "User wants 3 replicas â†’ Create/update ReplicaSet"               â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                 ReplicaSet Controller                                â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Watches: ReplicaSets                                              â”‚   â”‚
â”‚   â”‚   Creates: Pods                                                      â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   "ReplicaSet wants 3 pods, only 2 exist â†’ Create 1 more pod"      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                 Node Controller                                      â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Watches: Nodes                                                     â”‚   â”‚
â”‚   â”‚   Actions: Mark unhealthy, evict pods                               â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   "Node hasn't reported in 5 min â†’ Mark NotReady, evict pods"      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                 Service Controller                                   â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Watches: Services (type LoadBalancer)                             â”‚   â”‚
â”‚   â”‚   Creates: Cloud load balancers                                     â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   "Service type=LoadBalancer â†’ Create AWS ELB"                     â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                 Endpoint Controller                                  â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Watches: Services, Pods                                           â”‚   â”‚
â”‚   â”‚   Creates: Endpoints                                                 â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   "Service selects pods with app=nginx â†’ Update endpoints list"    â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚   And many more: Job, CronJob, StatefulSet, DaemonSet, Garbage Collection  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Module 5: Networking Internals (CNI)

## 5.1 Container Network Interface (CNI)

**Simple Explanation**: CNI is a standard for how container runtimes configure networking for containers. OpenShift uses OVN-Kubernetes as its CNI plugin.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CNI Plugin Flow                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   Pod created â†’ kubelet calls CNI plugin â†’ Network configured                â”‚
â”‚                                                                              â”‚
â”‚   1. kubelet: "I need to start pod X"                                        â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   2. CNI plugin: "I'll create network namespace"                            â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   3. CNI plugin: "I'll create veth pair (virtual ethernet)"                 â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚      â”‚  Pod namespace          â”‚    Host namespace                     â”‚    â”‚
â”‚      â”‚                         â”‚                                        â”‚    â”‚
â”‚      â”‚   eth0 â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  vethXXX                              â”‚    â”‚
â”‚      â”‚   10.128.1.5            â”‚    â”‚                                   â”‚    â”‚
â”‚      â”‚                         â”‚    â–¼                                   â”‚    â”‚
â”‚      â”‚                         â”‚  OVS Bridge                           â”‚    â”‚
â”‚      â”‚                         â”‚    â”‚                                   â”‚    â”‚
â”‚      â”‚                         â”‚    â–¼                                   â”‚    â”‚
â”‚      â”‚                         â”‚  Physical NIC                         â”‚    â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   4. CNI plugin: "I'll assign IP from IPAM (10.128.1.5)"                    â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   5. CNI plugin: "I'll configure routes and iptables"                       â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.2 OVN-Kubernetes Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OVN-Kubernetes Components                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   Control Plane:                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  OVN-Kubernetes Master                                              â”‚   â”‚
â”‚   â”‚  â€¢ Watches Kubernetes resources (pods, services, network policies)  â”‚   â”‚
â”‚   â”‚  â€¢ Programs OVN northbound database                                 â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  OVN Northbound Database                                            â”‚   â”‚
â”‚   â”‚  â€¢ Logical network topology                                         â”‚   â”‚
â”‚   â”‚  â€¢ Logical switches, routers, ACLs                                  â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼ (ovn-northd translates to southbound)                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  OVN Southbound Database                                            â”‚   â”‚
â”‚   â”‚  â€¢ Physical network bindings                                        â”‚   â”‚
â”‚   â”‚  â€¢ Flow rules                                                        â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚   Node Level:                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  ovn-controller (per node)                                          â”‚   â”‚
â”‚   â”‚  â€¢ Reads southbound database                                        â”‚   â”‚
â”‚   â”‚  â€¢ Programs OVS flows                                               â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚  Open vSwitch (OVS)                                                 â”‚   â”‚
â”‚   â”‚  â€¢ Actual packet forwarding                                         â”‚   â”‚
â”‚   â”‚  â€¢ Implements tunnels (GENEVE)                                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.3 Network Debugging

```bash
# Check pod network
oc exec my-pod -- ip addr
oc exec my-pod -- ip route
oc exec my-pod -- cat /etc/resolv.conf

# Check DNS resolution
oc exec my-pod -- nslookup kubernetes.default.svc.cluster.local

# Check connectivity
oc exec my-pod -- curl -v http://other-service:8080

# Debug network from node
oc debug node/node-1
chroot /host
ovs-vsctl show
ovs-ofctl dump-flows br-int | head -50

# Check OVN pods
oc get pods -n openshift-ovn-kubernetes

# Check network policy
oc get networkpolicy -n my-namespace

# TCP dump (on node)
tcpdump -i any port 8080
```

---

# Module 6: Storage Internals (CSI)

## 6.1 Container Storage Interface (CSI)

**Simple Explanation**: CSI is a standard for how Kubernetes talks to storage systems. Each storage provider has a CSI driver (AWS EBS, GCP PD, NFS, etc.).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CSI Architecture                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   PVC created â†’ CSI Provisioner â†’ Storage Backend â†’ PV created â†’ Mounted    â”‚
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    CSI Controller (Deployment)                       â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚   â”‚   â”‚  Provisioner    â”‚  â”‚   Attacher      â”‚  â”‚   Resizer       â”‚    â”‚   â”‚
â”‚   â”‚   â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚    â”‚   â”‚
â”‚   â”‚   â”‚  Creates/deletesâ”‚  â”‚  Attaches volumeâ”‚  â”‚  Resizes volume â”‚    â”‚   â”‚
â”‚   â”‚   â”‚  volumes        â”‚  â”‚  to nodes       â”‚  â”‚                 â”‚    â”‚   â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                               â”‚
â”‚                              â”‚ gRPC calls                                    â”‚
â”‚                              â–¼                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    CSI Driver Container                              â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Implements CSI spec:                                               â”‚   â”‚
â”‚   â”‚   â€¢ CreateVolume / DeleteVolume                                     â”‚   â”‚
â”‚   â”‚   â€¢ ControllerPublishVolume / ControllerUnpublishVolume            â”‚   â”‚
â”‚   â”‚   â€¢ NodeStageVolume / NodeUnstageVolume                             â”‚   â”‚
â”‚   â”‚   â€¢ NodePublishVolume / NodeUnpublishVolume                         â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                               â”‚
â”‚                              â”‚ API calls                                     â”‚
â”‚                              â–¼                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    Storage Backend                                   â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   AWS EBS, GCP PD, Azure Disk, NFS, Ceph, etc.                     â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 6.2 SPIFFE CSI Driver (What you used!)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SPIFFE CSI Driver                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   When pod mounts:                                                           â”‚
â”‚   volumes:                                                                   â”‚
â”‚   - name: spiffe-workload-api                                               â”‚
â”‚     csi:                                                                     â”‚
â”‚       driver: csi.spiffe.io                                                 â”‚
â”‚       readOnly: true                                                         â”‚
â”‚                                                                              â”‚
â”‚   SPIFFE CSI Driver:                                                         â”‚
â”‚   1. Creates a directory for this pod                                        â”‚
â”‚   2. Creates a Unix socket in that directory                                â”‚
â”‚   3. Connects socket to SPIRE Agent's Workload API                          â”‚
â”‚   4. Mounts directory into pod at specified path                            â”‚
â”‚                                                                              â”‚
â”‚   Result in pod:                                                             â”‚
â”‚   /spiffe-workload-api/                                                      â”‚
â”‚   â””â”€â”€ spire-agent.sock   â† Unix socket to SPIRE Agent                       â”‚
â”‚                                                                              â”‚
â”‚   Pod can then:                                                              â”‚
â”‚   â€¢ Request SVIDs via Workload API                                          â”‚
â”‚   â€¢ Get trust bundles                                                        â”‚
â”‚   â€¢ Validate other workloads' identities                                    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Module 7: Advanced Debugging

## 7.1 Systematic Debugging Approach

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Debugging Checklist                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   1. DESCRIBE - What does Kubernetes think is happening?                    â”‚
â”‚      oc describe pod/deployment/service <name>                              â”‚
â”‚      Look at: Events, Conditions, Status                                    â”‚
â”‚                                                                              â”‚
â”‚   2. LOGS - What is the application saying?                                 â”‚
â”‚      oc logs <pod> -c <container>                                           â”‚
â”‚      oc logs <pod> --previous   (crashed container)                         â”‚
â”‚                                                                              â”‚
â”‚   3. EVENTS - What happened recently?                                       â”‚
â”‚      oc get events --sort-by='.lastTimestamp'                               â”‚
â”‚                                                                              â”‚
â”‚   4. EXEC - What's happening inside?                                        â”‚
â”‚      oc exec -it <pod> -- /bin/bash                                         â”‚
â”‚      Check: processes, files, network, env                                  â”‚
â”‚                                                                              â”‚
â”‚   5. DEBUG - Access the node                                                â”‚
â”‚      oc debug node/<node>                                                   â”‚
â”‚      Check: kubelet, container runtime, system resources                    â”‚
â”‚                                                                              â”‚
â”‚   6. API - Is the object correct?                                           â”‚
â”‚      oc get <resource> -o yaml                                              â”‚
â”‚      Check: spec, status, annotations                                       â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 7.2 Common Issues and Solutions

### Pod Stuck in Pending

```bash
# Check why
oc describe pod <pod-name> | grep -A 20 "Events:"

# Possible causes:
# 1. Insufficient resources
oc describe node | grep -A 10 "Allocated resources:"

# 2. No nodes match selector
oc get nodes --show-labels | grep <required-label>

# 3. PVC pending
oc get pvc
oc describe pvc <pvc-name>

# 4. Image pull issues
oc describe pod <pod-name> | grep "Failed to pull"
```

### Pod Stuck in CrashLoopBackOff

```bash
# Check logs
oc logs <pod-name> --previous

# Check exit code
oc get pod <pod-name> -o jsonpath='{.status.containerStatuses[0].lastState.terminated.exitCode}'

# Common causes:
# Exit 1: Application error
# Exit 137: OOMKilled (memory limit hit)
# Exit 139: Segfault

# Check if OOMKilled
oc describe pod <pod-name> | grep OOMKilled
```

### Service Not Reaching Pods

```bash
# Check endpoints
oc get endpoints <service-name>
# If empty, selector doesn't match any pods

# Check labels match
oc get svc <service-name> -o jsonpath='{.spec.selector}'
oc get pods --show-labels

# Test from inside cluster
oc run debug --rm -it --image=busybox -- wget -qO- http://<service>:port

# Check NetworkPolicy
oc get networkpolicy -n <namespace>
```

## 7.3 Debug Commands Reference

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POD DEBUGGING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Describe pod
oc describe pod <pod>

# Get logs
oc logs <pod>
oc logs <pod> -c <container>
oc logs <pod> --previous
oc logs <pod> -f               # Follow
oc logs <pod> --tail=100       # Last 100 lines
oc logs <pod> --since=1h       # Last hour

# Execute in pod
oc exec -it <pod> -- /bin/bash
oc exec <pod> -- cat /app/config

# Copy files
oc cp <pod>:/path/to/file ./local-file
oc cp ./local-file <pod>:/path/to/file

# Port forward
oc port-forward <pod> 8080:80

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NODE DEBUGGING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Debug node (starts debug pod)
oc debug node/<node>
# Then: chroot /host

# Inside debug pod:
crictl ps                      # List containers
crictl logs <container-id>     # Container logs
journalctl -u kubelet         # Kubelet logs
systemctl status kubelet
ss -tulpn                      # Listening ports
df -h                          # Disk space
free -h                        # Memory

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLUSTER-WIDE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Events (cluster-wide)
oc get events -A --sort-by='.lastTimestamp' | tail -50

# All resources in namespace
oc get all -n <namespace>

# API resources
oc api-resources

# Check cluster operators (OpenShift)
oc get clusteroperators
oc describe clusteroperator <name>

# Cluster health
oc adm top nodes
oc adm top pods -A
```

---

# Module 8: Performance & Troubleshooting

## 8.1 Resource Management

```yaml
# Best practice: Always set requests AND limits
apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: my-app
    resources:
      requests:
        memory: "256Mi"    # Guaranteed minimum
        cpu: "250m"        # 0.25 CPU cores
      limits:
        memory: "512Mi"    # Maximum (OOMKilled if exceeded)
        cpu: "500m"        # Throttled if exceeded
```

## 8.2 Monitoring Commands

```bash
# Node resource usage
oc adm top nodes

# Pod resource usage
oc adm top pods -n <namespace>
oc adm top pods --containers  # Per container

# Resource quotas
oc describe resourcequota -n <namespace>

# Limit ranges
oc describe limitrange -n <namespace>

# Prometheus queries (via console or API)
# CPU usage: sum(rate(container_cpu_usage_seconds_total[5m])) by (pod)
# Memory: sum(container_memory_working_set_bytes) by (pod)
```

## 8.3 Performance Tuning Tips

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Performance Best Practices                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   1. Set appropriate resource requests/limits                               â”‚
â”‚      - Requests too low: Pod gets scheduled but starves                     â”‚
â”‚      - Requests too high: Wasted cluster capacity                           â”‚
â”‚      - Limits too low: OOMKilled/throttled                                  â”‚
â”‚      - Limits too high: One pod can starve others                          â”‚
â”‚                                                                              â”‚
â”‚   2. Use horizontal pod autoscaling                                         â”‚
â”‚      oc autoscale deployment my-app --min=2 --max=10 --cpu-percent=80      â”‚
â”‚                                                                              â”‚
â”‚   3. Use pod disruption budgets for availability                           â”‚
â”‚      Ensures minimum pods during updates/maintenance                        â”‚
â”‚                                                                              â”‚
â”‚   4. Use appropriate storage class                                          â”‚
â”‚      - SSD for databases                                                    â”‚
â”‚      - HDD for logs/backups                                                 â”‚
â”‚                                                                              â”‚
â”‚   5. Optimize container images                                              â”‚
â”‚      - Use minimal base images (UBI-minimal, Alpine)                        â”‚
â”‚      - Multi-stage builds                                                    â”‚
â”‚      - Don't include unnecessary tools                                      â”‚
â”‚                                                                              â”‚
â”‚   6. Use readiness/liveness probes properly                                 â”‚
â”‚      - Readiness: When to send traffic                                      â”‚
â”‚      - Liveness: When to restart                                            â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Quiz and Review

## Quiz Questions

1. **What are the stages of API request processing?**

2. **What happens if etcd is lost?**

3. **How does the scheduler decide where to place a pod?**

4. **What is CNI?**

5. **What does CSI stand for and what does it do?**

6. **How do you debug a pod that won't start?**

## Answers

1. Authentication â†’ Authorization (RBAC) â†’ Admission Control â†’ Storage (etcd)

2. All cluster state is lost. You need to restore from backup. This is why etcd backup is critical!

3. Filtering (which nodes CAN run it) â†’ Scoring (which is BEST) â†’ Binding

4. Container Network Interface - standard for container networking plugins

5. Container Storage Interface - standard for storage plugins (AWS EBS, GCP PD, etc.)

6. `oc describe pod`, check Events, `oc logs`, `oc get events`, check node resources

---

## Continuous Learning

Phase 4 is about ongoing deep learning. Keep exploring:

1. **Read source code** - Kubernetes is open source!
2. **Follow KEPs** - Kubernetes Enhancement Proposals
3. **Experiment** - Break things in a test cluster
4. **Contribute** - File bugs, improve docs
5. **Stay updated** - Follow release notes

---

**Congratulations! You've completed all four phases! ğŸ‰**

You now have a solid foundation in:
- âœ… Linux and Container fundamentals
- âœ… Kubernetes core concepts
- âœ… OpenShift enterprise features
- âœ… Operator Framework
- âœ… Cluster internals

Keep learning, keep building, keep breaking things! ğŸš€

---

*Phase 4 Complete! The journey continues...*
